import streamlit as st
from datetime import datetime
import base64

def save_function(model, temperature, template):
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"api_{model}_{current_time}.py"
    with open(filename, "w") as f:
        f.write("from langchain.prompts.prompt import PromptTemplate\n")
        f.write("from langchain.llms import OpenAI\n")
        f.write("from langchain.chains import ChatVectorDBChain\n")
        f.write("\n")
        f.write("import os\n")
        f.write("import pickle\n")
        f.write("from fastapi import FastAPI, Request\n")
        f.write("\n")
        f.write('os.environ["OPENAI_API_KEY"] = "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"\n')
        f.write("\n")
        f.write(f"model = '{model}'\n")
        f.write(f"temperature = {temperature}\n")
        f.write(f"template = '''{template}'''\n")
        f.write("\n")
        f.write("_template = '''Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n")
        f.write("you can assume the question is about the document.\n")
        f.write("\n")
        f.write("Chat History:\n")
        f.write("{chat_history}\n")
        f.write("Follow Up Input: {question}\n")
        f.write("Standalone question:'''\n")
        f.write("\n")
        f.write("CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n")
        f.write("\n")
        f.write("QA_PROMPT = PromptTemplate(template=template, input_variables=['question', 'context'])\n")
        f.write("\n")
        f.write('with open("vectorstore.pkl", "rb") as f:\n')
        f.write("   vectorstore = pickle.load(f)\n")
        f.write("\n")
        f.write("app = FastAPI()\n")
        f.write("llm = OpenAI(model=model, temperature=temperature)\n")
        f.write("qa_chain = ChatVectorDBChain.from_llm(\n")
        f.write("        llm,\n")
        f.write("        vectorstore,\n")
        f.write("        qa_prompt=QA_PROMPT,\n")
        f.write("        condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n")
        f.write("    )\n")
        f.write('@app.post("/api")\n')
        f.write("async def get_answer(request: Request):\n")
        f.write("    body = await request.json()\n")
        f.write('    question = body.get("question")\n')
        f.write('    chat_history = body.get("chat_history", [])\n')
        f.write('    result = qa_chain({"question": question, "chat_history": chat_history})\n')
        f.write('    chat_history.append((question, result["answer"]))\n')
        f.write('    return {"answer": result["answer"]}\n')
    st.success(f"Custom API created as {filename}")
    with open(f"{filename}", 'rb') as f:
        bytes = f.read()
    b64 = base64.b64encode(bytes).decode()
    href = f'<a href="data:file/{filename};base64,{b64}" download="{filename}">Download custom API</a>'
    st.markdown(href, unsafe_allow_html=True)